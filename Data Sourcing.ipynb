{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_log_data(gamelogs_url, year):\n",
    "    \n",
    "    #url = 'http://www.baseball-reference.com/players/gl.cgi?id=crawfbr01&t=b&year=2015'\n",
    "    url = gamelogs_url\n",
    "    #print url\n",
    "    r = requests.get(url)\n",
    "    #    print \"got to site\"\n",
    "    b = BeautifulSoup(r.text, 'html.parser')\n",
    "    HTML = r.text \n",
    "\n",
    "    #Initialize row identifier\n",
    "    RK = 1\n",
    "    end_of_table = False\n",
    "    my_log_data = {}\n",
    "    \n",
    "    #Declare a new instance of a Dataframe log\n",
    "    log_data = pd.DataFrame(columns=(\n",
    "        'RK', 'Gcar', 'Gtm', 'Date', 'Tm', 'HoA', 'Opp', 'Rslt',\n",
    "       'Inngs', 'PA', 'AB', 'R', 'H', 'Doubles', 'Tripples', 'HR',\n",
    "       'RBI', 'BB', 'IBB', 'SO', 'HBP', 'SH', 'SF', 'ROE', 'GDP',\n",
    "       'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS', 'BOP', 'aLI', 'WPA',\n",
    "       'RE24', 'DK', 'FD', 'Pos')\n",
    "    )\n",
    "    \n",
    "    #//thead/tr/th\n",
    "    columns = [''.join(td.xpath('.//text()').extract()) for td in Selector(text=HTML).xpath('//thead/tr/th')]\n",
    "    print(columns)\n",
    "    print(log_data.columns)\n",
    "    \n",
    "    #While RK is not null (i.e at the end of the table...)\n",
    "    #increment RK and collect pitching totals\n",
    "    while(end_of_table == False):\n",
    "\n",
    "        #Gate Keeping code to determine if while loop should proceed\n",
    "        try: \n",
    "            #This is where the table is found: //div[3]/div[2]/div/table/tbody/tr[1]/td\n",
    "            fields = [''.join(td.xpath('.//text()').extract()) for td in Selector(text=HTML).xpath('//div[3]/div[2]/div/table/tbody/tr['+str(RK)+']/td')]\n",
    "            print(\"There are {} fields. Here they are: {}\".format(len(fields), fields))\n",
    "            ahrefs = Selector(text=HTML).xpath('//div[3]/div[2]/div/table/tbody/tr['+str(RK)+']/td/a').extract()\n",
    "            row_number = fields[0].encode('utf-8').strip()\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                #Is this because we have encoutered a \"title\" row? As opposed to end of table?\n",
    "                fields = [''.join(td.xpath('.//text()').extract()) for td in Selector(text=HTML).xpath('//div[3]/div[2]/div/table/tbody/tr['+str(RK+1)+']/td')]\n",
    "                #fields = Selector(text=HTML).xpath('//div[3]/table/tbody/tr['+str(RK+1)+']/td/text()').extract()\n",
    "                ahrefs = Selector(text=HTML).xpath('//div[3]/div[2]/div/table/tbody/tr['+str(RK+1)+']/td/a').extract()\n",
    "                row_number = fields[0].encode('utf-8').strip()\n",
    "                print(fields)\n",
    "                \n",
    "                RK += 1\n",
    "            except:\n",
    "                #We have reached the end of the table\n",
    "                end_of_table = True\n",
    "                print(year, RK)\n",
    "\n",
    "        #print year, row_number, len(fields), len(ahrefs)\n",
    "        if len(fields) == 37:     #Table has DK, and FD information\n",
    "            print('37')\n",
    "   \n",
    "            if(row_number not in my_log_data.keys()):\n",
    "                \n",
    "                my_log_data[row_number] = {}\n",
    "                \n",
    "            if(fields[0] not in my_log_data[row_number].keys()):\n",
    "                my_log_data[row_number][columns[0]] = fields[0]\n",
    "                \n",
    "            end_of_table=True\n",
    "\n",
    "#             log_data.loc[row_number, \"Year\"] = year\n",
    "#             log_data.loc[row_number, \"RK\"] = row_number\n",
    "#             log_data.loc[row_number, \"Gcar\"] = fields[1]\n",
    "#             log_data.loc[row_number, \"Gtm\"] = fields[2].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Date\"] = fields[3].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Tm\"] = fields[4].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"HoA\"] = fields[5].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Opp\"] = fields[6].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Rsit\"] = fields[7].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Inngs\"] = fields[8].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"PA\"] = fields[9].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"AB\"] = fields[10].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"R\"] = fields[11].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"H\"] = fields[12].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Doubles\"] = fields[13].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Tripples\"] = fields[14].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"HR\"] = fields[15].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"RBI\"] = fields[16].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"BB\"] = fields[17].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"IBB\"] = fields[18].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"SO\"] = fields[19].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"HBP\"] = fields[20].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"SH\"] = fields[21].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"SF\"] = fields[22].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"ROE\"] = fields[23].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"GDP\"] = fields[24].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"SB\"] = fields[25].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"CS\"] = fields[26].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"BA\"] = fields[27].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"OBP\"] = fields[28].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"SLG\"] = fields[29].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"OPS\"] = fields[30].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"BOP\"] = fields[31].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"aLI\"] = fields[32].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"WPA\"] = fields[33].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"RE24\"] = fields[34].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"DK\"] = fields[35].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"FD\"] = fields[36].encode('utf-8').strip()\n",
    "#             log_data.loc[row_number, \"Pos\"] = fields[37].encode('utf-8').strip()\n",
    "            \n",
    "        elif len(fields) == 36:\n",
    "            print('36')\n",
    "            log_data.loc[row_number, \"Year\"] = year\n",
    "            log_data.loc[row_number, \"RK\"] = row_number\n",
    "            log_data.loc[row_number, \"Gcar\"] = fields[1].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Gtm\"] = fields[2].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Date\"] = fields[3].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Tm\"] = fields[4].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"HoA\"] = fields[5].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Opp\"] = fields[6].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Rsit\"] = fields[7].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Inngs\"] = fields[8].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"PA\"] = fields[9].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"AB\"] = fields[10].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"R\"] = fields[11].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"H\"] = fields[12].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Doubles\"] = fields[13].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"Tripples\"] = fields[14].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"HR\"] = fields[15].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"RBI\"] = fields[16].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"BB\"] = fields[17].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"IBB\"] = fields[18].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"SO\"] = fields[19].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"HBP\"] = fields[20].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"SH\"] = fields[21].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"SF\"] = fields[22].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"ROE\"] = fields[23].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"GDP\"] = fields[24].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"SB\"] = fields[25].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"CS\"] = fields[26].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"BA\"] = fields[27].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"OBP\"] = fields[28].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"SLG\"] = fields[29].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"OPS\"] = fields[30].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"BOP\"] = fields[31].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"aLI\"] = fields[32].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"WPA\"] = fields[33].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"RE24\"] = fields[34].encode('utf-8').strip()\n",
    "            log_data.loc[row_number, \"DK\"] = \"\"\n",
    "            log_data.loc[row_number, \"FD\"] = \"\"\n",
    "            log_data.loc[row_number, \"Pos\"] = fields[35].encode('utf-8').strip()\n",
    "        else:\n",
    "            exception_cases.append(row_number)\n",
    "        \n",
    "        RK += 1\n",
    "\n",
    "#         if RK > 3:\n",
    "#             end_of_table = True\n",
    "    \n",
    "    return my_log_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2011\">2011</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2012\">2012</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2013\">2013</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2014\">2014</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2015\">2015</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2016\">2016</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2017\">2017</a>', '<a href=\"/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=0&amp;post=1\">Postseason</a>']\n",
      "8\n",
      "http://www.baseball-reference.com/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2017\n"
     ]
    }
   ],
   "source": [
    "#Example for how to get game logs for a single player\n",
    "url = 'http://www.baseball-reference.com/players/gl.cgi?id=crawfbr01&t=b&year=2015'\n",
    "r = requests.get(url)\n",
    "#    print \"got to site\"\n",
    "b = BeautifulSoup(r.text, 'html.parser')\n",
    "HTML = r.text \n",
    "\n",
    "\n",
    "#xpath for Gamelogs:  //li[5]/div/ul[1]/li/a\n",
    "fields = Selector(text=HTML).xpath('//li[5]/div/ul[1]/li/a').extract()\n",
    "print(fields)\n",
    "print(len(fields))\n",
    "extracted_url = fields[len(fields)-2]\n",
    "\n",
    "try:\n",
    "    found = re.search('<a href=\"(.+?)\">', extracted_url).group(1)\n",
    "except AttributeError:\n",
    "    found = '' # apply some error handling\n",
    "#found\n",
    "\n",
    "#Concatenate the strings that will be used as full url to follow for data\n",
    "gamelogs_url = \"http://www.baseball-reference.com\" + found\n",
    "\n",
    "print(gamelogs_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rk', 'Gcar', 'Gtm', 'Date', 'Tm', '', 'Opp', 'Rslt', 'Inngs', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'BB', 'IBB', 'SO', 'HBP', 'SH', 'SF', 'ROE', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS', 'BOP', 'aLI', 'WPA', 'RE24', 'DFS(DK)', 'DFS(FD)', 'Pos']\n",
      "Index(['RK', 'Gcar', 'Gtm', 'Date', 'Tm', 'HoA', 'Opp', 'Rslt', 'Inngs', 'PA',\n",
      "       'AB', 'R', 'H', 'Doubles', 'Tripples', 'HR', 'RBI', 'BB', 'IBB', 'SO',\n",
      "       'HBP', 'SH', 'SF', 'ROE', 'GDP', 'SB', 'CS', 'BA', 'OBP', 'SLG', 'OPS',\n",
      "       'BOP', 'aLI', 'WPA', 'RE24', 'DK', 'FD', 'Pos'],\n",
      "      dtype='object')\n",
      "There are 37 fields. Here they are: ['810', '1', 'Apr 2', 'SFG', '@', 'ARI', 'L,5-6', 'CG', '5', '5', '1', '2', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '.400', '.400', '.600', '1.000', '5', '1.31', '-0.055', '-0.73', '', '', 'SS']\n",
      "37\n",
      "{b'810': {'Rk': '810'}}\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the strings that will be used as full url to follow for data\n",
    "#gamelogs_url = \"http://www.baseball-reference.com\" + found\n",
    "gamelogs_url = \"http://www.baseball-reference.com/players/gl.fcgi?id=crawfbr01&amp;t=b&amp;year=2017\"\n",
    "\n",
    "#years_of_interest = np.arange(2011, 2017, 1)\n",
    "years_of_interest = [2017]\n",
    "years_of_interest = sorted(years_of_interest, reverse=True)\n",
    "#years_of_interest\n",
    "\n",
    "batter_log = pd.DataFrame()\n",
    "buffer_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for year in years_of_interest:\n",
    "    url = gamelogs_url\n",
    "    #print url\n",
    "    try:\n",
    "        my_dict = get_log_data(url,year)\n",
    "        #buffer_df = get_log_data(url, year)\n",
    "        #batter_log = batter_log.append(buffer_df)\n",
    "\n",
    "    except:\n",
    "        #We have found a year log that does not exist for this player and it is likely that the preceeding years\n",
    "        #also do not exist...\n",
    "        break\n",
    "    \n",
    "#opponent = get_opposing_pitch_totals(url)\n",
    "\n",
    "print(my_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda3p5]",
   "language": "python",
   "name": "Python [conda3p5]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
